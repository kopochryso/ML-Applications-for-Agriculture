import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.inspection import permutation_importance

# -----------------------------
# 1. Load field + weather data
# -----------------------------
field = pd.read_csv(r"C:\Users\chryk\Downloads\Dataset\8_field_data.csv", sep=";", encoding="latin1")
weather = pd.read_csv(r"C:\Users\chryk\Downloads\Dataset\9_weather_data.csv", sep=";", encoding="latin1")

# Parse dates
field["date"] = pd.to_datetime(field["date"], dayfirst=True, errors="coerce")
weather["date"] = pd.to_datetime(weather["date"], dayfirst=True, errors="coerce")

# Merge on year, site_no, date
data = pd.merge(field, weather, on=["year", "site_no", "date"], how="left")

# -----------------------------
# 2. Define features & target
# -----------------------------
y = data["LAI"]
X = data.drop(columns=["LAI", "root_yield", "date"], errors="ignore")

numeric_features = X.select_dtypes(include=[np.number]).columns
categorical_features = X.select_dtypes(exclude=[np.number]).columns

# -----------------------------
# 3. Preprocessing
# -----------------------------
numeric_transformer = Pipeline([
    ("imputer", SimpleImputer(strategy="median"))
])

categorical_transformer = Pipeline([
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("encoder", OneHotEncoder(handle_unknown="ignore"))
])

preprocessor = ColumnTransformer([
    ("num", numeric_transformer, numeric_features),
    ("cat", categorical_transformer, categorical_features)
])

# -----------------------------
# 4. Train/test split
# -----------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# -----------------------------
# 5. RandomForest pipeline
# -----------------------------
rf_pipeline = Pipeline([
    ("preprocessor", preprocessor),
    ("regressor", RandomForestRegressor(n_estimators=300, random_state=42))
])

rf_pipeline.fit(X_train, y_train)
rf_preds = rf_pipeline.predict(X_test)

print("\nðŸŒ² RandomForest Results:")
print("RÂ²:", r2_score(y_test, rf_preds))
print("RMSE:", mean_squared_error(y_test, rf_preds, squared=False))

# Feature importances for RandomForest
rf_feature_names = rf_pipeline.named_steps["preprocessor"].get_feature_names_out()
rf_importances = pd.Series(
    rf_pipeline.named_steps["regressor"].feature_importances_,
    index=rf_feature_names[:len(rf_pipeline.named_steps["regressor"].feature_importances_)]
)

# -----------------------------
# 6. HistGradientBoosting pipeline
# -----------------------------
hgb_pipeline = Pipeline([
    ("preprocessor", preprocessor),
    ("regressor", HistGradientBoostingRegressor(random_state=42))
])

hgb_pipeline.fit(X_train, y_train)
hgb_preds = hgb_pipeline.predict(X_test)

print("\nðŸ“ˆ HistGradientBoosting Results:")
print("RÂ²:", r2_score(y_test, hgb_preds))
print("RMSE:", mean_squared_error(y_test, hgb_preds, squared=False))

# Permutation importance for HGB
hgb_result = permutation_importance(
    hgb_pipeline, X_test, y_test,
    n_repeats=10, random_state=42, n_jobs=-1
)

# Align feature names with actual transformed features
X_test_transformed = hgb_pipeline.named_steps["preprocessor"].transform(X_test)
hgb_feature_names = hgb_pipeline.named_steps["preprocessor"].get_feature_names_out()
hgb_feature_names = hgb_feature_names[:X_test_transformed.shape[1]]

hgb_importances = pd.Series(hgb_result.importances_mean, index=hgb_feature_names)

# -----------------------------
# 7. Plot comparison
# -----------------------------
fig, axes = plt.subplots(1, 2, figsize=(15, 6))

rf_importances.sort_values(ascending=True).tail(20).plot(
    kind="barh", ax=axes[0], title="RandomForest Feature Importances"
)
hgb_importances.sort_values(ascending=True).tail(20).plot(
    kind="barh", ax=axes[1], title="HistGradientBoosting Permutation Importances"
)

plt.tight_layout()
plt.show()
